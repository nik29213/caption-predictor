{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding,SimpleRNN,Dense\n",
    "from keras.models import *\n",
    "from keras.callbacks import ModelCheckpoint # save the best model, fight overfiitting\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout,LSTM,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_weights/model_8.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text and image processing using transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 38)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 38, 50)       92650       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 38, 50)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          314368      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1853)         476221      dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,473,575\n",
      "Trainable params: 1,380,925\n",
      "Non-trainable params: 92,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_temp = ResNet50(weights=\"imagenet\",input_shape=(224,224,3))\n",
    "model.summary()\n",
    "#resnet will be used for just feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = Model(model_temp.input,model_temp.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    img = image.load_img(img,target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img,axis=0) \n",
    "    #bcz img may b needed to b feed in batches .so its dim will become(n,224,224,3).so expand_im is used\n",
    "    img = preprocess_input(img)#predefined func of keras\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_img(img):\n",
    "    img = preprocess_img(img)\n",
    "    feature_vector = model_resnet.predict(img)\n",
    "    feature_vector = feature_vector.reshape((1,feature_vector.shape[1]))\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_img(\"elephant.jpg\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_weights/wrd2idx.pkl\",\"rb\") as w2i:\n",
    "    word2idx=pickle.load(w2i)\n",
    "with open(\"model_weights/idx2wrd.pkl\",\"rb\") as i2w:\n",
    "    idx2word=pickle.load(i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 38\n",
    "def predict_caption(photo):\n",
    "    in_text = \"startseq\"\n",
    "    for i in range(max_len):\n",
    "        sequence = [word2idx[w] for w in in_text.split() if w in word2idx]\n",
    "        sequence = pad_sequences([sequence],maxlen = max_len,padding = \"post\")\n",
    "        #print(sequence)\n",
    "        ypred = model.predict([photo,sequence])\n",
    "        #print(\"ypred = \",str(ypred))\n",
    "        ypred = ypred.argmax()\n",
    "        #print(\"ypred = \",str(ypred))\n",
    "        word = idx2word[ypred]\n",
    "        in_text+=(\" \" + word)\n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "    final_caption = in_text.split()[1:-1]#remove startseq nd endseq\n",
    "    final_caption = \" \".join(final_caption)\n",
    "        \n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_this_img(imgnm):    \n",
    "    img = encode_img(imgnm)\n",
    "    caption = predict_caption(img)\n",
    "    return caption\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
